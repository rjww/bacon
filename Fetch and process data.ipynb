{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960...\n",
      "970...\n",
      "980...\n",
      "990...\n",
      "1000...\n",
      "1010...\n",
      "1020...\n",
      "1030...\n",
      "1040...\n",
      "1050...\n",
      "1060...\n",
      "1070...\n",
      "1080...\n",
      "1090...\n",
      "1100...\n",
      "1110...\n",
      "1120...\n",
      "1130...\n",
      "1140...\n",
      "1150...\n",
      "1160...\n",
      "1170...\n",
      "1180...\n",
      "1190...\n",
      "1200...\n",
      "1210...\n",
      "1220...\n",
      "1230...\n",
      "1240...\n",
      "1250...\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import tmdbsimple as tmdb\n",
    "\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "\n",
    "tmdb.API_KEY = os.environ.get('TMDB_API_KEY', None)\n",
    "\n",
    "queued_films = set()\n",
    "if os.path.isfile('./data/static/queued_films.pickle'):\n",
    "    with open('./data/static/queued_films.pickle', 'rb') as file:\n",
    "        queued_films = pickle.load(file)\n",
    "\n",
    "seen_films = set()\n",
    "if os.path.isfile('./data/static/seen_films.pickle'):\n",
    "    with open('./data/static/seen_films.pickle', 'rb') as file:\n",
    "        seen_films = pickle.load(file)\n",
    "\n",
    "rejected_films = set()\n",
    "if os.path.isfile('./data/static/rejected_films.pickle'):\n",
    "    with open('./data/static/rejected_films.pickle', 'rb') as file:\n",
    "        rejected_films = pickle.load(file)\n",
    "\n",
    "nodes = {}\n",
    "if os.path.isfile('./data/static/nodes.pickle'):\n",
    "    with open('./data/static/nodes.pickle', 'rb') as file:\n",
    "        nodes = pickle.load(file)\n",
    "\n",
    "edges = {}\n",
    "if os.path.isfile('./data/static/edges.pickle'):\n",
    "    with open('./data/static/edges.pickle', 'rb') as file:\n",
    "        edges = pickle.load(file)\n",
    "\n",
    "\n",
    "film_ids = list(queued_films - seen_films - rejected_films)\n",
    "\n",
    "\n",
    "for film_id in film_ids:\n",
    "    try:\n",
    "        credits = tmdb.Movies(film_id).credits()\n",
    "    except (HTTPError, ValueError):\n",
    "        rejected_films.add(film_id)\n",
    "        continue\n",
    "        \n",
    "    for person in credits['cast']:\n",
    "        nodes.update({\n",
    "            person['id']: {\n",
    "                'name': person['name'],\n",
    "                'gender': person['gender']}})\n",
    "        \n",
    "    cast_ids = [person['id'] for person in credits['cast']]\n",
    "    \n",
    "    for combination in itertools.combinations(cast_ids, 2):\n",
    "        if combination[0] == combination[1]:\n",
    "            continue\n",
    "        \n",
    "        pair = frozenset(combination)\n",
    "        \n",
    "        if pair in edges:\n",
    "            edges[pair] += 1\n",
    "        else:\n",
    "            edges[pair] = 1\n",
    "            \n",
    "    seen_films.add(film_id)\n",
    "    \n",
    "    if len(seen_films) % 10 == 0:\n",
    "        with open('./data/static/seen_films.pickle', 'wb') as file:\n",
    "            pickle.dump(seen_films, file)\n",
    "        \n",
    "        with open('./data/static/rejected_films.pickle', 'wb') as file:\n",
    "            pickle.dump(rejected_films, file)\n",
    "        \n",
    "        with open('./data/static/nodes.pickle', 'wb') as file:\n",
    "            pickle.dump(nodes, file)\n",
    "        \n",
    "        with open('./data/static/edges.pickle', 'wb') as file:\n",
    "            pickle.dump(edges, file)\n",
    "            \n",
    "        print('{}...'.format(len(seen_films)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open('./data/static/nodes.pickle', 'rb') as infile, open('./data/static/nodes.csv', 'w') as outfile:\n",
    "    nodes = pickle.load(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    writer.writerow(['ID', 'Label', 'Gender'])\n",
    "    \n",
    "    for tmdb_id, person in nodes.items():\n",
    "        writer.writerow([tmdb_id, person['name'], person['gender']])\n",
    "    \n",
    "    \n",
    "with open('./data/static/edges.pickle', 'rb') as infile, open('./data/static/edges.csv', 'w') as outfile:\n",
    "    edges = pickle.load(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    writer.writerow(['Source', 'Target', 'Weight'])\n",
    "    \n",
    "    for pair, weight in edges.items():\n",
    "        nodes = [x for x in pair]\n",
    "        \n",
    "        if len(nodes) != 2:\n",
    "            continue\n",
    "        \n",
    "        writer.writerow([nodes[0], nodes[1], weight])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
